{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GHDIYQElU0r"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from urllib.parse import urlparse\n",
        "import sys\n",
        "\n",
        "#Define the base URL\n",
        "base_url = \"https://www.polovniautomobili.com/auto-oglasi/pretraga?page={}&sort=basic&city_distance=0&showOldNew=all&without_price=1\"\n",
        "\n",
        "#Define a list to store the scraped data\n",
        "data = []\n",
        "\n",
        "#Define headers to mimic a browser request\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
        "}\n",
        "\n",
        "#Loop through the pages\n",
        "for page in range(1, 50):\n",
        "    sys.stdout.write(f\"\\rScraping page {page}...\")\n",
        "    sys.stdout.flush()\n",
        "    for attempt in range(5):  # maximum 5 attempts\n",
        "        try:\n",
        "            #Send a GET request\n",
        "            response = requests.get(base_url.format(page), headers=headers)\n",
        "\n",
        "            #Parse the HTML content\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            #Find all divs with the class 'textContentHolder'\n",
        "            divs = soup.find_all('div', class_='textContentHolder')\n",
        "\n",
        "            #Loop through the divs and extract the data\n",
        "            for div in divs:\n",
        "                name = div.find('a', class_='ga-title')\n",
        "                price = div.find('div', class_='price')\n",
        "\n",
        "                top_details = div.find_all('div', class_='top')\n",
        "                kilometers = ''\n",
        "                year = ''\n",
        "                type = ''\n",
        "                for detail in top_details:\n",
        "                    title = detail.get('title')\n",
        "                    if title is not None:\n",
        "                        if 'km' in title:\n",
        "                            kilometers = detail.text.strip()\n",
        "                        elif '.' in title:  # Assuming year will always have a dot.\n",
        "                            year, type = detail.text.strip().split('.', 1)\n",
        "\n",
        "                bottom_details = div.find('div', class_='bottom')\n",
        "                hidden_details = div.find('div', class_='bottom uk-hidden-medium uk-hidden-small')\n",
        "\n",
        "                if name and price and kilometers and year and type and bottom_details and hidden_details:\n",
        "                    #Extract the link\n",
        "                    parsed_url = urlparse(name['href'])\n",
        "                    link = \"https://www.polovniautomobili.com\" + parsed_url.path\n",
        "\n",
        "                    #Split the bottom details into two parts at the '|'\n",
        "                    if '|' in bottom_details.text:\n",
        "                        bottom_part1, bottom_part2 = bottom_details.text.split('|', 1)\n",
        "                    else:\n",
        "                        bottom_part1 = bottom_details.text\n",
        "                        bottom_part2 = ''\n",
        "\n",
        "                    data.append({\n",
        "                        'Vozilo': name.text.strip(),\n",
        "                        'Cena': price.text.strip(),\n",
        "                        'Godina': year,\n",
        "                        'Tip vozila': type.strip(),\n",
        "                        'Kilometraza': kilometers,\n",
        "                        'B/D': bottom_part1.strip(),\n",
        "                        'Kubika': bottom_part2.strip(),\n",
        "                        'KS': hidden_details.text.strip(),\n",
        "                        'Link': link\n",
        "                    })\n",
        "\n",
        "            time.sleep(random.uniform(0.5, 1.2))\n",
        "            break  #if the request was successful, break out of the loop\n",
        "        except (requests.exceptions.ChunkedEncodingError, requests.exceptions.ConnectionError):\n",
        "            if attempt < 4:  #if not the last attempt\n",
        "                time.sleep(2**(attempt+1))  # exponential backoff\n",
        "                continue\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "#Convert the list to a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "#Write the DataFrame to an Excel file\n",
        "df.to_excel('scraped_data.xlsx', index=False)\n"
      ]
    }
  ]
}